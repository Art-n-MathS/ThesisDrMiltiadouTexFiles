\documentclass{subfiles}

\begin{document}
	
	\par As mentioned in Section \ref{sec:Problem}, there are very few uses of FW LiDAR data because of the quantity of the recorded information. For that reason, DASOS was developed (Section \ref{DASOS}) as an open source software, to help foresters without computer science background to use FW LiDAR data while simultaneously advancing the research goals of this thesis.  In this section:
	
	\begin{itemize}
		\item An overview of related software packages is given and we explain how DASOS differs from those packages (Section \ref{LiDARsoftwares}).
		\item The main method of interpreting the data within DASOS (the voxelisation approach) is described (Subsection \ref{Voxelisation}).
		\item All the functionalities of DASOS are listed (Section \ref{DASOS})
		\item and, finally, a summary is provided (Section \ref{DASOS-Vol-Summary}).
	\end{itemize}
	
	
	
	
	\section{State-of-Art FW LiDAR Software Packages}\label{LiDARsoftwares}
	
	\par The most common approach for interpreting FW LiDAR is the Gaussian decomposition of the waveforms for peak-points extraction. Each waveform is modelled as a set of Gaussian pulses and for every Gaussian peak, a single return (equivalent to a discrete LiDAR point) is extracted ~\cite{Wanger2006}. Neunschwander et al used this approach for Landcover classification ~\cite{Neuenschwander2009} while Reitberger et al applied it for distinguishing deciduous trees from coniferous trees ~\cite{Reitberger2008}. Chauve et al further proposed an approach of improving the Gaussian model in order to increase the density of the points extracted from the data and consequently improve point based classifications of FW LiDAR data ~\cite{Chauve2007}.  The following tools are able to extract discrete points from the waveforms and visualise small areas of interest:


	\begin{itemize}
		\item \textbf{Pulsewaves}: visualises a small number of waveforms using different transparencies according to the intensities of the wave-samples and is able to generate discrete point clouds \cite{Isenburg2012Pulsewaves}. \newline Link: \url{<https://rapidlasso.com/pulsewaves/>}
	    \item \textbf{FullAnalyze}: supports echo decomposition. Regarding visualisations, the user can select single trees from the Graphical User Interface (GUI) and, for each wave-sample, a sphere with radius proportional to its amplitude is created and visualised \cite{Chauve2009}. \newline Link: \url{<http://fullanalyze.sourceforge.net/>} 
    	\item \textbf{SPDlib}: exports discrete LiDAR from the waveforms and visualises either the samples that are above a threshold level as points or the extracted discrete point cloud. It also colours them according to their intensity value\cite{Bunting2013}. \newline Link: \url{<http://www.spdlib.org/>} 
	\end{itemize}

	\par Echo decomposition and extraction of peak points identifies significant features and further enables the interpretation of the data within existing workflows and software that support discrete LiDAR data. For example, the discrete LiDAR can be analysed using: 
	
	\begin{itemize}
	\item \textbf{Lag}: a visualisation tool for analysing and inspecting discrete LiDAR point clouds. \newline Link: \url{<http://arsf.github.io/lag/>}
	
	\item \textbf{Quick Terrain Modeller} : a 3D discrete LiDAR points visualiser, that can generate Digital Elevation Models (DEM) and Digital Terrain Models (DTM). \newline Link: \url{<http://appliedimagery.com/>}
	
	\item \textbf{LAStools} : a tool set that classifies noise, visualises point clouds, clips data.  \newline Link \url{{<https://rapidlasso.com/lastools/>}}
	\end{itemize}
		
	\par The DASOS approach to interpreting FW LiDAR data is fundamentally different from the aforementioned software packages. On the one hand, converting FW LiDAR into discrete peaks eases their usage, since existing workflows support discrete LiDAR.  On the other hand, FW LiDAR contains information about pulse width that is usually not preserved after peak point extraction. Also the comparison of point clouds depends on the density of the emitted pulses; problems arise with the sinusoidal scannng pattern of, for example, the Leica system, resulting in higher numbers of samples at the edges of the swath and lower in the middle. For these reasons, in DASOS, this information is accumulated from multiple shots into a voxel array, building up a 3D density volume. The correlation between multiple pulses in a voxel representation produces a more accurate and complete representation, which confers greater noise resistance and it further opens up possibilities of vertical interpretation of the data. The idea of voxelising FW LiDAR data is explained in the following section \ref{Voxelisation}.  
	
		
	 \section{Voxelisation for Interpreting FW LiDAR data}\label{Voxelisation}
		
	\par Voxelisation of FW LiDAR data was first introduced by Persson et al., who used it to visualise waveforms using different transparencies \cite{Persson2005} and it has been adopted as the future of FW LiDAR data with the literature moving toward that direction. In 2016-17, Cao et al used it for tree species identification \cite{Cao2016}, Hancock et al improved canopy height models of vegetation \cite{Hancock2017}  and Sunmall et al characterised forest canopy from a voxelised vertical profile \cite{Sumnall2016}. This innovative approach of voxelising the FW LiDAR data is an integral part of this thesis and it is used for both visualisations and classifications \cite{Miltiadou2014}\cite{Miltiadou2015}. 

	\par The FW LiDAR data are voxelised by inserting the wave samples into a 3D regular grid and constructing a 3D discrete density volume. According to Persson et al, each wave sample is associated with the 3D cell, named voxel, that it lies inside. If multiple samples lie inside a voxel then the sample with the highest intensity is chosen \cite{Persson2005}. In order to reduce noise, there are two differences between this approach and the way FW LiDAR data are voxelised in DASOS.
	
	\par At first a threshold is used to remove low level noise, because when the length of a recorded waveform is longer than the distance between the first hit point and the ground, the system captures low signals for the remaining sampling time period after the pulse has been absorbed by the ground, which results pure noise. For that reason, the samples whose intensity is lower than a user-defined noise level/threshold are discarded. 
		

		\par As before, each wave sample is associated with the voxel that it lies inside.  The second difference is how DASOS overcomes the uneven number of samples per voxels, which is primarily caused by the differing angle at which the LiDAR shot passes through voxels directly below the sensor and those off to the sides. The intensity of each sample is the laser intensity returned during the corresponding time interval. For example, if 5 samples are inside a voxel and the waveform is digitised at 2ns, then the laser intensity associated with that voxel corresponds to a 10ns waveform sampling length. For comparison purposes, it's essential to keep the waveform length consistent across the voxels. To overcome this issue in DASOS, the average intensity of the samples that lie inside each voxel is taken, instead of choosing the one with the highest intensity \cite{Persson2005}. This way, the likelihood that the 3D volume will be affected by outliers and high noise is reduced. The following equation shows how the intensity value of a voxel is calculated:
		
		\begin{eqnarray}
		I_{v} = \dfrac{\sum_{i=1}^{n}I_{i}}{n}
		\end{eqnarray} 
		where 		$I_{v}$ is the accumulated intensity of voxel $v$,
		$n$ is number of samples associated with that voxel and
		$I_{i}$ is the intensity of the sample i.
		
		To sum up, during voxelisation, the area of interest is divided into voxels. The samples of the FW LiDAR data are inserted inside this 3D discrete density volume and normalised such that equally sized waveform length is saved inside each voxel. The result is a 3D discrete density volume of the scanned area. Figure \ref{fig:Voxelisation} depicts this process in 2D.
		
		%\afterpage
		{
		\begin{figure} [h!]			
			\begin{subfigure}[t]{.31\textwidth}
				
				\centering
				\includegraphics[width=.9\textwidth]{img/VoxelisationA}
				\caption{The sensor from the plane emits multiple pulses and collects information from the returned laser intensity.}
				\label{fig:VoxelisationA_scan}
			\end{subfigure} \hfill
			\begin{subfigure}[t]{.31\textwidth}
				\centering
				\includegraphics[width=.9\textwidth]{img/VoxelisationB}
				\caption{The area of interest is divided into equally sized cubes, named voxels, generating this way a discrete volume.} 
				\label{fig:VoxelisationB_grid}
			\end{subfigure} \hfill
			\begin{subfigure}[t]{.31\textwidth}
				\centering
				\includegraphics[width=.9\textwidth]{img/VoxelisationC}
				\caption{The accumulated intensities of wave samples into the volume build up the voxelised representation of the scanned area.} 
				\label{fig:VoxelisationC_voxelised}
			\end{subfigure}
			\caption[Voxelisation of FW LiDAR data]{The above images depict the voxelisation process of the FW LiDAR data in 2D. Please note that the voxelisation output in Figure \ref{fig:VoxelisationC_voxelised} shows how ideally the result would look. But in reality, a number of trees may be disconnected from the ground due to missing information about their trunk. \footnotemark }  
			\label{fig:Voxelisation} 
		\end{figure}
		
		\footnotetext{The tree and plane images are taken from: http://images.clipartpanda.com/tree-clip-artKij4jKriq.jpeg  \& http://gmv.cast.uark.edu/wpcontent/uploads/2013/01/ALS\_scematic.jpg  }
	}
			

	\section{The functionalities of DASOS}\label{DASOS}
	
		\par So far, an overview of existing software packages supporting FW LiDAR was given (Section \ref{LiDARsoftwares}) and it was explained how DASOS differs from them by voxelising the waveforms (Section \ref{Voxelisation}). In this section, the three main functionalities of DASOS are described in Tables \ref{tbl:functionality1}, \ref{tbl:functionality2} and \ref{tbl:functionalities}.
		
	  	\par Each functionality is linked to a number of thesis sections, which describe the algorithms implemented and the related applications. In a few words, the 3D visualisations are useful in forestry for reducing fieldwork and improving planning of field trips (e.g. checking whether a road passes through a fieldplot area). The 2D metrics allow simultaneous interpretation of FW LiDAR data and hyperspectral imagery. They could also be used in GIS software. In this thesis, they are used for generating tree coverage maps. Last, but not least, are the vector features that enable 3D feature detection and are used for detecting dead standing trees.

        		\begin{longtable}
        			{| p{0.08\linewidth}|p{0.3\linewidth}  | p{0.4\linewidth} | p{0.1\linewidth}|  }
        			\toprule
        			\multicolumn{4}{|c|}{\textbf{First Functionality: 3D Polygon Mesh Generation }} \\
        			\toprule
        			\textbf{Input}&\textbf{Description} & \textbf{Output Example} & \textbf{Output Format} \\ 
        			\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        			LAS1.3& \textbf{3D Polygon Mesh } \newline Constructed from the volumetric representation (algorithms and user-defined parameters are explained in Section \ref{Visualisations} while optimisation approaches are discussed in Section \ref{Optimisations}) \newline & \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={0 {0.37\width} 0 0},clip]{img/NewForest}} & .obj \\ 
        			
        			\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        			LAS1.3 \newline and \newline level 1 (.bil \& .igm& \textbf{ 3D Coloured \newline Polygon Mesh } \newline Projecting 3 user-defined hyperspectral bands on the mesh (Section \ref{Alignment}) \newline & \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={0 0 0 {0.41\width}},clip]{img/NewForest}} & .obj \newline \& \newline .png \\ 
        			
        			\bottomrule
        			
        			\multicolumn{4}{c}{} \\
        				\caption{The 1st functionality of DASOS that generates 3D polygonal meshes.}
        				\label{tbl:functionality1}
        				
        		\end{longtable}
        			\newpage
        				\begin{longtable}
        					{| p{0.08\linewidth}|p{0.3\linewidth}  | p{0.4\linewidth} | p{0.1\linewidth}|  }
        			%%
        			\toprule
        			\multicolumn{4}{|c|}{\textbf{Second Functionality: Generation of 2D metrics}} \\
        			\multicolumn{4}{|c|}{\textbf{aligned with hyperspectral imagery }} \\
        			\toprule

					\multicolumn{4}{|c|}{In Section \ref{Alignment} a selection of the following metrics are used} \\
					\multicolumn{4}{|c|}{for generating tree coverage maps} \\

        				%%
        		
        		
        		
        		        		
        		\toprule
        		\textbf{Input}&\textbf{Metric Description} \newline (L for LiDAR metrics \& H for hyperspectral metrics) & \textbf{Output Example} & \textbf{Output Format} \\ 
        		
        			%%
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3& \textbf{L0 - Digital Elevation Model - DEM: } \newline The distance between the top non-empty voxel and the lower boundaries of the volume.& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/HEIGHT}} & .asc \\ 
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3& \textbf{L1 - Thickness: } \newline The distance between  the  first  and  last  non  empty  voxels  in every   column of the   3D   volume.& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/THICKNESS}} & .asc \\ 
        		
        	
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}				
        		LAS1.3& \textbf{L2 - Density:} \newline Number of non-empty voxel over all voxels within  the  range  from the first to last non-empty voxels. &       \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/DENSITY}} & .asc \\ 
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3& \textbf{L3 - First Patch: } \newline The number of non-empty adjacent voxels, starting from the top non-empty voxel in that column. &         					\raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/FIRST_PATCH}} & .asc \\ 
        		
        
        			
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3& \textbf{L4: Last Patch: } \newline The number of non-empty adjacent voxels, starting from   the lower   non-empty   voxel in   that column.& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/LAST_PATCH}} & .asc \\
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3&   \textbf{L5 - Edge detection:}\newline The average height difference of neighbouring pixels &         	\raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/AverageHeightDiff}} & .asc \\ 
        				
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3& \textbf{L6: Lowest Return } \newline The height of the lowest non empty voxel&  \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/LOWEST_RETURN}} & .asc \\
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3& \textbf{L7: Maximum \newline Intensity } \newline The maximum intensity of each column& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/metric_INTENSITY_MAX}} & .asc \\
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3& \textbf{L8: Average Intensity } \newline The average intensity per column& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/metric_INTENSITY_AVG}} & .asc \\
        		
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3 \newline and \newline level 1 (.bil \& .igm) & \textbf{H0 : Mean } \newline The mean of the hyperspectral spectrum.& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/HYPERSPECTRAL_MEAN}} & .asc \\ 
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        			LAS1.3 \newline and \newline level 1 (.bil \& .igm) &\textbf{H1: Standard \newline Deviation \footnotemark[1]} \newline The standard deviation of the hyperspectral spectrum at each pixel.& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/std}} & .asc \\ 
        			
        			\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3 \newline and \newline level 1 (.bil \& .igm) &\textbf{H2: NDVI } \newline The Normalised Difference Vegetation Index indicates whether green vegetation exists or not and it is derived from the electromagnetic spectrum as follow:
        		    \begin{eqnarray}
        		    NDVI = \dfrac{NIR-VIS}{NIR+VIS}
        		    \end{eqnarray}
        		    where the NIR is the near-infrared region of the spectrum (700-2500nm) and VIS is the Visible/Visual spectrum (430-770nm) 
        		     \cite{Crippen1990_NDVI}.& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/NDVI}} & .asc \\ 
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        	
        		LAS1.3 \newline and \newline level 1 (.bil \& .igm) &\textbf{H3: Spectral \newline Signature \footnotemark[1]} \newline The   squared spectral   difference   between   each pixels’  spectrum  and the  generalised vegetation signature retrieved  from  USGS  Digital  Spectral Library \cite{Clark2007}.& \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/spectralSignature}} & .asc  \\ 
        		
        		
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3 \newline and \newline level 1 (.bil \& .igm) &\textbf{H4: Band} \newline A single user defined hyperspectral band. & \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/hy35}} & .asc \\ 
				& & \raisebox{-\totalheight}{\adjincludegraphics[width=\linewidth,trim={{.1\width} 0 {.25\width} 0},clip]{img/metrics/hy235}} & .asc \\ 
        		
        		%%
        		
        		\bottomrule	
        		\caption[DASOS's functionalities]{The 2nd functionality of DASOS that generates 2D metrics in ASCII format.}
        		\label{tbl:functionality2}	
        	\end{longtable}
        	
	\footnotetext[1]{The marked metrics of Table \ref{tbl:functionality2} were implemented specifically for the tree coverage maps \cite{Miltiadou2015} and they are not available on the released version of DASOS.}
	
	
      			\begin{longtable}
  				{| p{0.08\linewidth}|p{0.3\linewidth}  | p{0.4\linewidth} | p{0.1\linewidth}|  }
        		\toprule
        		\multicolumn{4}{|c|}{\textbf{Third Functionality: 3D Priors / Signatures }} \\
        		\toprule
        		\multicolumn{4}{|c|}{The list of feature vectors that characterise objects or local areas in 3D. }  \\
        		\multicolumn{4}{|c|} In Section \ref{Classifications}, the list of feature vectors are used to described dead trees and they \\
       			\multicolumn{4}{|c|}are compared across the voxelised space for detecting dead standing trees \\
        		\toprule
        		\textbf{Input}&\textbf{Description} & \textbf{Output Example} & \textbf{Output Format} \\ 
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3 & \textbf{List of feature vectors} \newline with raw intensities & Please Look at Figure \ref{fig:PriorRaw} & .csv \\
        		\cmidrule(r){1-1}\cmidrule(lr){2-2}\cmidrule(lr){3-3}\cmidrule(l){4-4}
        		LAS1.3 & \textbf{List of feature vectors} \newline with processed intensities & Please Look at Figure \ref{fig:PriorProcessed}  & .csv \\
        		
        		
        		\bottomrule
        		
        		
        		
        		\caption[DASOS's functionalities]{The three functionalities of DASOS}
				\label{tbl:functionalities}	
        	\end{longtable}
        	
		

        
        	\begin{figure} [h!]
        		\centering
        		\includegraphics[width=\textwidth]{img/PriorsRaw}
        		\caption{Example of an exported .csv file that contains a list of feature vectors with raw voxel intensities}
        		\label{fig:PriorRaw}
        	\end{figure}		
        	\begin{figure} [h!]
        		\centering
        		\includegraphics[width=\textwidth]{img/PriorsProcessed}
        		\caption{Example of exported .csv file that contains a list of feature vectors with processed information about voxels' intensities.}
        		\label{fig:PriorProcessed}
        	\end{figure}	
        	
        		
	   	
	 
	   \newpage
	   	\par The complete user guide of DASOS is given in Appendix \ref{DASOS_userGuide}. The user guide gives an in-depth explanation on how to use the available commands and variables to generate 3D coloured polygonal meshes, 2D metrics algined with hyperspectral imagery and lists of feature vectors.  It also provides information on how to download DASOS with its source code and on what relevant forums exists for providing support.
	   
	  \section{Summary and Discussion} \label{DASOS-Vol-Summary}
	  
	   	\par Along with supporting the research in this thesis, the open source software DASOS was developed to encourage foresters to use FW LiDAR data. The main way of interpreting FW LiDAR data in DASOS is fundamentally different from the state-of-art available software packages. In a few words, the FW LiDAR data are voxelised by inserting the wave samples into a 3D discrete density volume, which preserves an extra parameter (the echo width) in comparison to point extraction algorithms. It also accumulates intensity values from multiple shots and stores them into a 3D regular grid, resolving this way the problem with the sinusoidal footprint / uneven scanning pattern of the Leica system.
	   	
	   	\par There are three main functionalities of DASOS: the construction of 3D polygon meshes, the generation of 2D metrics aligned with hyperspectral images and characterisation of objects using feature vectors. The visualisation outputs are also state-of-art since previous visualisations talk about points \cite{Bunting2013} or spheres \cite{Chauve2009}, while DASOS is able to create closed polygon representation. In addition, the integration of various sensors allows simultaneous interpretation of their data and, in section \ref{Alignment}, it is shown that this confers better results for generating tree coverage maps. The last feature of DASOS allow local inspection of data and they are used in section \ref{Classifications} for dead standing tree detection in native Australian forests.
	   		
	   	\par Finally, it worth mentioning that there a few individuals/organisation that showed interest in using DASOS and, in the future, usage of it, it derivatives or the concepts employed in it are expected to increase in remote forest surveys (i.e. for commercial forest stocking estimation or for infected trees detection and treatment).
	   	
\end{document}